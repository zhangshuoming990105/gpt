# manual optimize GPT like LLM using optimizations

## we target on the attention block optimization for simplicity

## currently we probably will test on:

- [v] pytorch cpu
- [v] pytorch gpu
- [v] tvm cpu
- [v] tvm gpu
- [v] naive cpu implementation
- [v] naive gpu implementation
- [x] optimized gpu implementation
- [x] autotvm gpu
- [x] ansor gpu
